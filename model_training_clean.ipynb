{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_TVTkdzhGNW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8o5iLXtX2K7"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets pandas\n",
        "!pip install evaluate datasets\n",
        "!pip install transformers[torch] accelerate -U\n",
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yFmTijr-12d"
      },
      "outputs": [],
      "source": [
        "# unzip the folder and save the data\n",
        "!unzip /content/drive/MyDrive/boundary_demarcation/Planet/DATA_full/planet_patches_png.zip -d /content/drive/MyDrive/boundary_demarcation/Planet/DATA_full/Images\n",
        "!unzip /content/drive/MyDrive/boundary_demarcation/Planet/DATA_full/planet_masks_png.zip -d /content/drive/MyDrive/boundary_demarcation/Planet/DATA_full/Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55m8ZfA37wG4"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import cv2\n",
        "import tifffile\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import concurrent.futures\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from transformers import (\n",
        "    SegformerForSemanticSegmentation,\n",
        "    TrainingArguments, Trainer,\n",
        "    SegformerImageProcessor)\n",
        "from datasets import Dataset, Image\n",
        "import evaluate\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "botHeTSP7xdW"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = 12, 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRb_s_aRP7U1"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = Path('/content/drive/MyDrive/boundary_demarcation/Planet/DATA_full')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTAAv4c_P7rr"
      },
      "outputs": [],
      "source": [
        "# Pre-trained models\n",
        "MODEL_CHECKPOINT = 'nvidia/mit-b4'\n",
        "\n",
        "\n",
        "VAL_SIZE = 0.2\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 10\n",
        "LR = 0.00006\n",
        "\n",
        "IMG_SIZE = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDX2ZBqAkECq"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WHAlvvwdlE3"
      },
      "outputs": [],
      "source": [
        "# Combine the base directory with the 'Images' subdirectory\n",
        "images_path = DATA_DIR / 'Images'\n",
        "images = list(images_path.glob('**/*.png'))\n",
        "images = [str(path) for path in images]\n",
        "print(f'{len(images)} images detected.')\n",
        "\n",
        "# Combine the base directory with the 'Masks' subdirectory\n",
        "masks_path = DATA_DIR / 'Masks'\n",
        "masks = list(masks_path.glob('**/*.png'))\n",
        "masks = [str(path) for path in masks]\n",
        "print(f'{len(masks)} masks detected.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyKiTFQn_aY-"
      },
      "outputs": [],
      "source": [
        "# Ensure the image and mask paths are sorted consistently\n",
        "images.sort()\n",
        "masks.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLen9kyJvFm9"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and validation sets\n",
        "\n",
        "train_images, val_images, train_masks, val_masks = train_test_split(\n",
        "    images, masks, test_size=VAL_SIZE, random_state=0, shuffle=True)\n",
        "print(f'Train images: {len(train_images)}\\nValidation images: {len(val_images)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luvsDxKGJ849"
      },
      "outputs": [],
      "source": [
        "# check the training masks\n",
        "train_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48EBncquvOAF",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def create_dataset(image_paths, mask_paths):\n",
        "    dataset = Dataset.from_dict({'pixel_values': image_paths,\n",
        "                                 'label': mask_paths})\n",
        "    dataset = dataset.cast_column('pixel_values', Image())\n",
        "    dataset = dataset.cast_column('label', Image())\n",
        "    return dataset\n",
        "\n",
        "\n",
        "ds_train = create_dataset(train_images, train_masks)\n",
        "ds_valid = create_dataset(val_images, val_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmwAUDsYKclB"
      },
      "outputs": [],
      "source": [
        "ds_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hSb10J3K8bJ"
      },
      "outputs": [],
      "source": [
        "ds_valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG2LLLHmLeJ-"
      },
      "source": [
        "### display and check images and masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klOGwiQnYcZh"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the image file\n",
        "image_path = '/content/drive/MyDrive/boundary_demarcation/results/water/53987_image.tif'\n",
        "\n",
        "# Path to the image file\n",
        "mask_path = '/content/drive/MyDrive/boundary_demarcation/results/water/53987_mask.png'\n",
        "\n",
        "\n",
        "# Read the image using tifffile\n",
        "image = tifffile.imread(image_path)\n",
        "# Read the image using OpenCV\n",
        "mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6, 6))\n",
        "\n",
        "# Display the image\n",
        "ax1.imshow(image)\n",
        "ax1.set_title('Image')\n",
        "ax1.axis('Off')  # Turn off axis\n",
        "\n",
        "\n",
        "# Display the image\n",
        "# ax2.imshow(mask)\n",
        "ax2.imshow(mask, cmap='Blues')\n",
        "ax2.set_title('Mask')\n",
        "ax2.axis('Off')  # Turn off axis\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQLU7GFCYwJC"
      },
      "outputs": [],
      "source": [
        "np.unique(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQz1E-URjdQp"
      },
      "outputs": [],
      "source": [
        "# Get the properties of the image\n",
        "height, width, channels = image.shape\n",
        "data_type = image.dtype\n",
        "\n",
        "print(f'Image Dimensions: {width}x{height}')\n",
        "print(f'Number of Channels: {channels}')\n",
        "print(f'Data Type: {data_type}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLx0djDIcRfg"
      },
      "source": [
        "## ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao0lKRZnQAHD"
      },
      "outputs": [],
      "source": [
        "# Image preprocessing native to the pretrained model.\n",
        "feature_extractor = SegformerImageProcessor.from_pretrained(MODEL_CHECKPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFaAxDgZvb8h"
      },
      "outputs": [],
      "source": [
        "# apply transformations to the image\n",
        "def apply_transforms(batch):\n",
        "    images = [x for x in batch['pixel_values']]\n",
        "    labels = [x for x in batch['label']]\n",
        "    inputs = feature_extractor(images, labels)\n",
        "    return inputs\n",
        "\n",
        "\n",
        "ds_train.set_transform(apply_transforms)\n",
        "ds_valid.set_transform(apply_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYZxG5PYvdl9"
      },
      "outputs": [],
      "source": [
        "ds_train, ds_valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee7DAKaQvk46"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8qF5q_FvmWa"
      },
      "outputs": [],
      "source": [
        "# for rgb water\n",
        "id2label = {0: 'background', 1: 'water'}\n",
        "\n",
        "label2id = {label: id for id, label in id2label.items()}\n",
        "num_labels = len(id2label)\n",
        "\n",
        "model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "    MODEL_CHECKPOINT,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kb7Im4GvvF5"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load('mean_iou')\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    with torch.no_grad():\n",
        "        logits, labels = eval_pred\n",
        "        logits_tensor = torch.from_numpy(logits)\n",
        "        # scale the logits to the size of the label\n",
        "        logits_tensor = nn.functional.interpolate(\n",
        "            logits_tensor,\n",
        "            size=labels.shape[-2:],\n",
        "            mode='bilinear',\n",
        "            align_corners=False,\n",
        "        ).argmax(dim=1)\n",
        "\n",
        "        pred_labels = logits_tensor.detach().cpu().numpy()\n",
        "        metrics = metric._compute(\n",
        "                predictions=pred_labels,\n",
        "                references=labels,\n",
        "                num_labels=len(id2label),\n",
        "                ignore_index=0,\n",
        "                reduce_labels=feature_extractor.do_reduce_labels,\n",
        "            )\n",
        "\n",
        "        # add per category metrics as individual key-value pairs\n",
        "        per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
        "        per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
        "\n",
        "        metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
        "        metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
        "\n",
        "        return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2-9ghyIvxIB"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    'segformer_finetuned_water_planet_RGB_fullimage_2607',\n",
        "    learning_rate=LR,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    save_total_limit=3,\n",
        "    evaluation_strategy='steps',\n",
        "    save_strategy='steps',\n",
        "    save_steps=20,\n",
        "    eval_steps=20,\n",
        "    logging_steps=1,\n",
        "    eval_accumulation_steps=5,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        "    report_to='none'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-qPxTTsyRf6"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=ds_train,\n",
        "    eval_dataset=ds_valid,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK_XJzSiMwi8"
      },
      "outputs": [],
      "source": [
        "# save the trained model\n",
        "model.save_pretrained('/content/drive/MyDrive/MA/Models/segformer_finetuned_water_planet_RGB_fullimage_2607')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtEPh3f3Hpt6",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "id2label = {0: 'background', 1: 'water'}\n",
        "label2id = {label: id for id, label in id2label.items()}\n",
        "num_labels = len(id2label)\n",
        "\n",
        "model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "   '/content/drive/MyDrive/MA/Models/segformer_finetuned_water_planet_RGB_fullimage_2607',\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")\n",
        "\n",
        "\n",
        "feature_extractor = SegformerImageProcessor.from_pretrained(MODEL_CHECKPOINT)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualise and compare the satellite image, true mask and predicted mask"
      ],
      "metadata": {
        "id": "ov_Bn_5g7gVU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7q5_M2GHtdb"
      },
      "outputs": [],
      "source": [
        "for i in range(len(val_images)):\n",
        "    image_path = val_images[i]\n",
        "    mask_path = val_masks[i]\n",
        "\n",
        "    image = tifffile.imread(image_path)\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
        "    print(f'Validation image #{i + 1}')\n",
        "\n",
        "    inputs = np.moveaxis(image, -1, 0)\n",
        "    inputs = feature_extractor(images=image, return_tensors='pt')\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    # Rescale logits to original image size\n",
        "    upsampled_logits = nn.functional.interpolate(\n",
        "        logits,\n",
        "        size=image.shape[:-1], # (height, width)\n",
        "        mode='bilinear',\n",
        "        align_corners=False\n",
        "    )\n",
        "\n",
        "    # Apply argmax on the class dimension\n",
        "    pred_mask = upsampled_logits.argmax(dim=1)[0]\n",
        "\n",
        "\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\n",
        "\n",
        "    ax1.imshow(image)\n",
        "    ax1.set_title('Image')\n",
        "    ax1.axis('Off')\n",
        "\n",
        "    ax2.imshow(mask, cmap='Blues')\n",
        "    ax2.set_title('True mask')\n",
        "    ax2.axis('Off')\n",
        "\n",
        "    ax3.imshow(pred_mask, cmap='Blues')\n",
        "    ax3.set_title('Predicted mask')\n",
        "    ax3.axis('Off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAJRiVl4Vy2i"
      },
      "outputs": [],
      "source": [
        "val_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56eSOAaXWC6I"
      },
      "outputs": [],
      "source": [
        "val_masks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### predict and save all images"
      ],
      "metadata": {
        "id": "oz6hMk9mT0AT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tifffile\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as nnf\n",
        "from PIL import Image\n",
        "\n",
        "def save_predictions(val_images, val_masks, model, feature_extractor, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for i in range(len(val_images)):\n",
        "        image_path = val_images[i]\n",
        "        mask_path = val_masks[i]\n",
        "\n",
        "        image = tifffile.imread(image_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
        "        print(f'Validation image #{i + 1}')\n",
        "\n",
        "        inputs = np.moveaxis(image, -1, 0)\n",
        "        inputs = feature_extractor(images=image, return_tensors='pt')\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Rescale logits to original image size\n",
        "        upsampled_logits = nnf.interpolate(\n",
        "            logits,\n",
        "            size=image.shape[:-1], # (height, width)\n",
        "            mode='bilinear',\n",
        "            align_corners=False\n",
        "        )\n",
        "\n",
        "        # Apply argmax on the class dimension\n",
        "        pred_mask = upsampled_logits.argmax(dim=1)[0].cpu().numpy()\n",
        "\n",
        "        # Create the output file path with '_pred' attached to the original mask name\n",
        "        mask_name = os.path.basename(mask_path)\n",
        "        mask_name_without_ext, ext = os.path.splitext(mask_name)\n",
        "        pred_mask_name = f\"{mask_name_without_ext}_pred.png\"\n",
        "        pred_mask_path = os.path.join(output_folder, pred_mask_name)\n",
        "\n",
        "        # Save the predicted mask as a PNG file\n",
        "        pred_mask_image = Image.fromarray(pred_mask.astype(np.uint8))\n",
        "        pred_mask_image.save(pred_mask_path)\n",
        "\n",
        "        # Display the images and masks\n",
        "        fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\n",
        "\n",
        "        ax1.imshow(image)\n",
        "        ax1.set_title('Image')\n",
        "        ax1.axis('Off')\n",
        "\n",
        "        ax2.imshow(mask, cmap='Blues')\n",
        "        ax2.set_title('True mask')\n",
        "        ax2.axis('Off')\n",
        "\n",
        "        ax3.imshow(pred_mask, cmap='Blues')\n",
        "        ax3.set_title('Predicted mask')\n",
        "        ax3.axis('Off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "output_folder = \"/content/drive/MyDrive/MA/Output/Prediction_masks\"\n",
        "\n",
        "\n",
        "save_predictions(val_images, val_masks, model, feature_extractor, output_folder)"
      ],
      "metadata": {
        "id": "mV3Fi2LnT1Ii"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}