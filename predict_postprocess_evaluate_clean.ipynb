{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4etMiegoVRu46DGNSXMId"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Predict for test site images using the saved model"
      ],
      "metadata": {
        "id": "dXgNwHeu5_Lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/boundary_demarcation/Planet/DATA_Test/planet_testsite_patches_png.zip -d /content/drive/MyDrive/boundary_demarcation/Planet/DATA_Test/\n",
        "!unzip /content/drive/MyDrive/boundary_demarcation/Planet/DATA_Test/planet_testsite_patches_tiff.zip -d /content/drive/MyDrive/boundary_demarcation/Planet/DATA_Test/"
      ],
      "metadata": {
        "id": "D43CegKy5_Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# search all files inside a specific folder\n",
        "# *.* means file name with any extension\n",
        "dir_path =  \"/content/drive/MyDrive/boundary_demarcation/Planet/DATA_Test/planet_testsite_patches_png/*\"\n",
        "\n",
        "# Use glob to find all the files matching the pattern\n",
        "test_images_names = glob.glob(dir_path, recursive=True)\n",
        "test_images_names"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FPJ6MVI-5_Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_images_names)"
      ],
      "metadata": {
        "id": "rV4m-Aok5_Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = test_images_names"
      ],
      "metadata": {
        "id": "QemWhLe55_Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model\n",
        "\n",
        "id2label = {0: 'background', 1: 'water'}\n",
        "label2id = {label: id for id, label in id2label.items()}\n",
        "num_labels = len(id2label)\n",
        "\n",
        "model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "   '/content/drive/MyDrive/MA/Models/segformer_finetuned_water_planet_RGB_fullimage_2607',\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")\n",
        "\n",
        "\n",
        "feature_extractor = SegformerImageProcessor.from_pretrained(MODEL_CHECKPOINT)"
      ],
      "metadata": {
        "id": "Sk0lv-Lq6l_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tifffile\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as nnf\n",
        "from PIL import Image\n",
        "\n",
        "def save_predictions(val_images, model, feature_extractor, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for i in range(len(val_images)):\n",
        "        image_path = val_images[i]\n",
        "        #mask_path = val_masks[i]\n",
        "\n",
        "        image = tifffile.imread(image_path)\n",
        "        #mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
        "        print(f'Validation image #{i + 1}')\n",
        "\n",
        "        inputs = np.moveaxis(image, -1, 0)\n",
        "        inputs = feature_extractor(images=image, return_tensors='pt')\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Rescale logits to original image size\n",
        "        upsampled_logits = nnf.interpolate(\n",
        "            logits,\n",
        "            size=image.shape[:-1], # (height, width)\n",
        "            mode='bilinear',\n",
        "            align_corners=False\n",
        "        )\n",
        "\n",
        "        # Apply argmax on the class dimension\n",
        "        pred_mask = upsampled_logits.argmax(dim=1)[0].cpu().numpy()\n",
        "\n",
        "        # Create the output file path with '_pred' attached to the original mask name\n",
        "        image_name = os.path.basename(image_path)\n",
        "        image_name_without_ext, ext = os.path.splitext(image_name)\n",
        "        pred_mask_name = f\"{image_name_without_ext}_pred.png\"\n",
        "        pred_mask_path = os.path.join(output_folder, pred_mask_name)\n",
        "\n",
        "        # Save the predicted mask as a PNG file\n",
        "        pred_mask_image = Image.fromarray(pred_mask.astype(np.uint8))\n",
        "        pred_mask_image.save(pred_mask_path)\n",
        "\n",
        "        # Display the images and masks\n",
        "        fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\n",
        "\n",
        "        ax1.imshow(image)\n",
        "        ax1.set_title('Image')\n",
        "        ax1.axis('Off')\n",
        "\n",
        "        ax2.imshow(pred_mask, cmap='Blues')\n",
        "        ax2.set_title('Predicted mask')\n",
        "        ax2.axis('Off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "output_folder = \"/content/drive/MyDrive/boundary_demarcation/Planet/RESULTS/TEST_SITE/TestSite_Prediction_masks\"\n",
        "\n",
        "# Assume `model` and `feature_extractor` are defined and initialized\n",
        "save_predictions(val_images, model, feature_extractor, output_folder)"
      ],
      "metadata": {
        "id": "77f8yduwqcRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directory = \"/content/drive/MyDrive/boundary_demarcation/Planet/RESULTS/TEST_SITE/TestSite_Prediction_masks\"\n",
        "lst = os.listdir(directory) # your directory path\n",
        "number_files = len(lst)\n",
        "print( number_files)"
      ],
      "metadata": {
        "id": "x_YJFB6o40wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7MeNzFkraZ8"
      },
      "source": [
        "## apply majority filter on the predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwoTjOIPriv5"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.filters.rank import modal\n",
        "from skimage.morphology import rectangle\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def apply_modal_filter(image, footprint_size=(3, 3)):\n",
        "    # Apply the modal filter\n",
        "    result = modal(image, rectangle(*footprint_size))\n",
        "    return result\n",
        "\n",
        "def process_images(input_dir, output_dir, footprint_size=(3, 3)):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Get all image files in the input directory\n",
        "    image_paths = glob.glob(os.path.join(input_dir, '*.png'))\n",
        "    # print(image_paths)\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        # Read the input image\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Apply the modal filter\n",
        "        result = apply_modal_filter(image, footprint_size)\n",
        "        result = apply_modal_filter(result, footprint_size)\n",
        "        result = apply_modal_filter(result, footprint_size)\n",
        "\n",
        "        # Save the filtered result as a JPEG image\n",
        "        base_name = os.path.basename(image_path)\n",
        "        output_path = os.path.join(output_dir, f\"{os.path.splitext(base_name)[0]}_majority.png\")\n",
        "        cv2.imwrite(output_path, result)\n",
        "\n",
        "        # Plot the original and filtered images\n",
        "        plt.figure(figsize=(14, 10))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title('Original Image')\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(result, cmap='gray')\n",
        "        plt.title('Filtered Image')\n",
        "        plt.show()\n",
        "\n",
        "# Paths\n",
        "input_dir = \"/content/drive/MyDrive/boundary_demarcation/Planet/Results/predicted_masks_test\"\n",
        "output_dir = '/content/drive/MyDrive/boundary_demarcation/Planet/Results/predicted_masks_majority_test'\n",
        "\n",
        "# Process all images in the input directory\n",
        "process_images(input_dir, output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQdmq0Ai0O5M"
      },
      "source": [
        "## convert predicted masks (majority applied) to shapefile"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fetch projection and transform from TIFF image and add to shapefile"
      ],
      "metadata": {
        "id": "1ieumOU9n30H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/boundary_demarcation/Planet/DATA_full/planet_patches_tiff.zip -d /content/drive/MyDrive/boundary_demarcation/Planet/DATA_full/planet_patches_tiff"
      ],
      "metadata": {
        "collapsed": true,
        "id": "axspidgmyhRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Polygon\n",
        "import os\n",
        "import rasterio\n",
        "from rasterio.transform import Affine\n",
        "from shapely.ops import transform\n",
        "from pyproj import Transformer\n",
        "\n",
        "# Function to read and process each mask image\n",
        "def process_mask(mask_path):\n",
        "    # Read the binary mask image\n",
        "    binary_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Ensure the binary mask is binary (0 or 255)\n",
        "    #_, binary_mask = cv2.threshold(binary_mask, 0.5, 1, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Find contours in the binary mask\n",
        "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Convert valid contours to polygons\n",
        "    polygons = []\n",
        "    for cnt in contours:\n",
        "        if len(cnt) >= 4:  # Ensure the contour has at least 4 points\n",
        "            polygon = Polygon(cnt.reshape(-1, 2))\n",
        "            polygons.append(polygon)\n",
        "\n",
        "    return polygons\n",
        "\n",
        "# Function to transform the polygon coordinates based on the affine transform\n",
        "def apply_affine_transform(polygon, affine_transform):\n",
        "    transformed_coords = [affine_transform * (x, y) for x, y in polygon.exterior.coords]\n",
        "    return Polygon(transformed_coords)\n",
        "\n",
        "# Directory where the mask images are saved\n",
        "mask_dir = \"/content/drive/MyDrive/boundary_demarcation/Planet/RESULTS/TEST_SITE/TestSite_Prediction_masks\"\n",
        "vec_dir  = \"/content/drive/MyDrive/boundary_demarcation/Planet/RESULTS/TEST_SITE/TestSite_Predicted_vectors\"\n",
        "tiff_dir = \"/content/drive/MyDrive/boundary_demarcation/Planet/DATA_Test/planet_testsite_patches_tiff\"  # Directory where the TIFF files are saved\n",
        "\n",
        "# List of mask image filenames\n",
        "mask_filenames = [f for f in os.listdir(mask_dir) if f.endswith('.png')]\n",
        "\n",
        "# Process each mask image and save as an individual shapefile\n",
        "for mask_filename in mask_filenames:\n",
        "    mask_path = os.path.join(mask_dir, mask_filename)\n",
        "    polygons = process_mask(mask_path)\n",
        "\n",
        "    # Corresponding TIFF filename (removing '_pred' from the mask filename)\n",
        "    tiff_filename = mask_filename.replace('_pred.png', '') + '.tif'\n",
        "    tiff_path = os.path.join(tiff_dir, tiff_filename)\n",
        "\n",
        "    # Check if the TIFF file exists\n",
        "    if not os.path.exists(tiff_path):\n",
        "        print(f\"TIFF file not found: {tiff_path}\")\n",
        "        continue\n",
        "\n",
        "    # Read the projection information and affine transform from the TIFF file\n",
        "    with rasterio.open(tiff_path) as src:\n",
        "        crs = src.crs\n",
        "        affine_transform = src.transform\n",
        "\n",
        "    # Transform the polygons to the correct coordinates\n",
        "    transformed_polygons = [apply_affine_transform(polygon, affine_transform) for polygon in polygons]\n",
        "\n",
        "    # Initialize the transformer\n",
        "    transformer = Transformer.from_crs(crs, 'EPSG:4326', always_xy=True)\n",
        "\n",
        "    # Convert the transformed polygons to the desired CRS (WGS 84)\n",
        "    wgs84_polygons = [transform(transformer.transform, polygon) for polygon in transformed_polygons]\n",
        "\n",
        "    # Save polygons to a GeoDataFrame\n",
        "    gdf = gpd.GeoDataFrame(geometry=wgs84_polygons, crs='EPSG:4326')\n",
        "\n",
        "    # Define output shapefile path\n",
        "    output_shapefile_path = os.path.join(vec_dir, f'{os.path.splitext(mask_filename)[0]}.shp')\n",
        "\n",
        "    # Save the GeoDataFrame to a shapefile\n",
        "    gdf.to_file(output_shapefile_path)\n",
        "\n",
        "    # Print confirmation\n",
        "    print(f'Saved {output_shapefile_path}')"
      ],
      "metadata": {
        "id": "XnHE4y-KoMms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation on Val Set"
      ],
      "metadata": {
        "id": "OWor4WoJCNvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
        "import seaborn as sns\n",
        "\n",
        "def compute_test_metrics(model, feature_extractor, test_images, test_masks, id2label):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for i in range(len(test_images)):\n",
        "        image_path = test_images[i]\n",
        "        mask_path = test_masks[i]\n",
        "\n",
        "        image = tifffile.imread(image_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "        # Preprocess the image\n",
        "        inputs = feature_extractor(images=image, return_tensors='pt')\n",
        "\n",
        "        # Get the model output\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Rescale logits to original image size\n",
        "            upsampled_logits = nn.functional.interpolate(\n",
        "                logits,\n",
        "                size=image.shape[:-1], # (height, width)\n",
        "                mode='bilinear',\n",
        "                align_corners=False\n",
        "            )\n",
        "\n",
        "            # Apply argmax on the class dimension\n",
        "            pred_mask = upsampled_logits.argmax(dim=1)[0].cpu().numpy()\n",
        "\n",
        "        # Flatten the masks for metric calculations\n",
        "        all_preds.extend(pred_mask.flatten())\n",
        "        all_labels.extend(mask.flatten())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds, labels=list(id2label.keys()))\n",
        "\n",
        "    # Compute precision, recall, f1-score\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, labels=list(id2label.keys()), average=None)\n",
        "\n",
        "    # Compute IoU\n",
        "    iou_scores = {}\n",
        "    for i, label in id2label.items():\n",
        "        intersection = np.logical_and(all_labels == i, all_preds == i).sum()\n",
        "        union = np.logical_or(all_labels == i, all_preds == i).sum()\n",
        "        iou_scores[label] = intersection / union if union != 0 else 0\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, labels=list(id2label.keys()), target_names=list(id2label.values())))\n",
        "\n",
        "    print(\"\\nIoU Scores:\")\n",
        "    for label, iou in iou_scores.items():\n",
        "        print(f\"{label}: {iou:.4f}\")\n",
        "\n",
        "    # Visualization of the confusion matrix\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", xticklabels=id2label.values(), yticklabels=id2label.values())\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Assuming you have already loaded your validation or test data\n",
        "compute_test_metrics(model, feature_extractor, val_images, val_masks, id2label)"
      ],
      "metadata": {
        "id": "X8HdYdibx9GL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# percentage confusion matrix\n",
        "\n",
        "# Convert to row-wise percentages\n",
        "conf_matrix_percent = conf_matrix.astype('float') / conf_matrix.sum(axis=1, keepdims=True) * 100\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(conf_matrix_percent, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=['Background', 'Water'],\n",
        "            yticklabels=['Background', 'Water'])\n",
        "\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix (%)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3JZsqBqqyZ40"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}